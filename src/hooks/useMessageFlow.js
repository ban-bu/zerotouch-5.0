import { useState, useCallback } from 'react'
import { processWithLLM } from '../services/llmService'

export const useMessageFlow = (currentScenario) => {
  const [messages, setMessages] = useState({
    problem: [],
    llm: [],
    solution: []
  })
  const [llmProcessing, setLlmProcessing] = useState(false)
  const [llmProcessingContext, setLlmProcessingContext] = useState(null) // 'problem' | 'solution' | null
  const [iterationProcessing, setIterationProcessing] = useState(false) // æ–°å¢ï¼šè¿­ä»£å¤„ç†çŠ¶æ€
  const [iterationMode, setIterationMode] = useState(false) // æ–°å¢ï¼šè¿­ä»£æ¨¡å¼çŠ¶æ€
  const [pendingResponse, setPendingResponse] = useState(null) // æ–°å¢ï¼šå¾…å‘é€çš„å“åº”
  
  // æ–°å¢ï¼šéœ€æ±‚åˆ†æç›¸å…³çŠ¶æ€
  const [missingInfoOptions, setMissingInfoOptions] = useState([])
  const [showMissingInfoPanel, setShowMissingInfoPanel] = useState(false)
  const [currentNeedsAnalysis, setCurrentNeedsAnalysis] = useState(null)

  // æ–°å¢ï¼šæ¥å—è¿½é—®åç›´å‘å€™é€‰ï¼ˆç”¨äºå¯¹æ¯”ç¡®è®¤ï¼‰
  const [directSendCandidate, setDirectSendCandidate] = useState(null)

  const addMessage = useCallback((panel, message) => {
    setMessages(prev => ({
      ...prev,
      [panel]: [...prev[panel], message]
    }))
  }, [])

  const clearMessages = useCallback(() => {
    setMessages({
      problem: [],
      llm: [],
      solution: []
    })
    setIterationMode(false)
    setPendingResponse(null)
    setLlmProcessing(false)
    setLlmProcessingContext(null)
  }, [])

  // å‘é€å®¢æˆ·å›å¤åˆ°é—®é¢˜ç«¯ï¼ˆä¸è§¦å‘è½¬è¯‘ï¼‰
  const sendCustomerReplyToProblem = useCallback((messageData) => {
    const customerReplyMessage = {
      type: 'ai_response', // æ ‡è®°ä¸ºAIå›å¤ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥
      text: messageData.text,
      timestamp: messageData.timestamp,
      source: 'customer_reply' // æ ‡è®°æ¥æº
    }
    addMessage('problem', customerReplyMessage)
  }, [addMessage])

  const sendProblemMessage = useCallback(async (messageData) => {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°é—®é¢˜ç«¯
    const userMessage = {
      type: 'user',
      text: messageData.text,
      image: messageData.image,
      timestamp: messageData.timestamp
    }
    addMessage('problem', userMessage)

    // å¼€å§‹LLMå¤„ç†ï¼ˆé—®é¢˜ç«¯ â†’ æ–¹æ¡ˆç«¯ï¼‰
    setLlmProcessingContext('problem')
    setLlmProcessing(true)

    try {
      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å² - åŒ…å«æ‰€æœ‰çœŸå®çš„å¯¹è¯å†…å®¹
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' })),
        userMessage // åŒ…å«å½“å‰æ¶ˆæ¯ï¼ˆç”¨æˆ·ï¼‰
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ä½¿ç”¨æ–°çš„æ™ºèƒ½éœ€æ±‚åˆ†æ
      const llmResult = await processWithLLM({
        type: 'analyze_needs_with_missing_info',
        content: messageData.text,
        image: messageData.image,
        context: 'problem_to_solution',
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // ä¿å­˜å½“å‰éœ€æ±‚åˆ†æç»“æœ
      setCurrentNeedsAnalysis({
        originalContent: messageData.text,
        image: messageData.image,
        chatHistory: chatHistory
      })

      // è®¾ç½®ç¼ºå¤±ä¿¡æ¯é€‰é¡¹
      setMissingInfoOptions(llmResult.missingInfoOptions || [])
      
      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'æ™ºèƒ½éœ€æ±‚åˆ†æ',
        steps: [
          {
            name: 'éœ€æ±‚ç†è§£',
            content: llmResult.needsUnderstanding
          },
          {
            name: 'éœ€æ±‚è½¬è¯‘',
            content: llmResult.translation
          },
          {
            name: 'ç¼ºå¤±ä¿¡æ¯åˆ†æ',
            content: llmResult.missingInfoOptions && llmResult.missingInfoOptions.length > 0 
              ? `è¯†åˆ«åˆ° ${llmResult.missingInfoOptions.length} ä¸ªå¯äº†è§£çš„ä¿¡æ¯ç‚¹ï¼Œç­‰å¾…ä¼ä¸šæ–¹é€‰æ‹©`
              : 'éœ€æ±‚ä¿¡æ¯è¾ƒä¸ºå®Œæ•´ï¼Œæ— éœ€é¢å¤–äº†è§£ä¿¡æ¯'
          }
        ],
        output: llmResult.translation,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // æ·»åŠ ç¿»è¯‘åçš„æ¶ˆæ¯åˆ°æ–¹æ¡ˆç«¯
      const translatedMessage = {
        type: 'llm_request',
        text: llmResult.translation,
        timestamp: new Date().toISOString(),
        needsAnalysis: llmResult.needsUnderstanding,
        missingInfoOptions: llmResult.missingInfoOptions || []
      }
      addMessage('solution', translatedMessage)

      // å¦‚æœæœ‰ç¼ºå¤±ä¿¡æ¯é€‰é¡¹ï¼Œæ˜¾ç¤ºå‹¾é€‰é¢æ¿
      if (llmResult.missingInfoOptions && llmResult.missingInfoOptions.length > 0) {
        setShowMissingInfoPanel(true)
      }

    } catch (error) {
      console.error('LLMå¤„ç†é”™è¯¯:', error)
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage = {
        type: 'processing',
        title: 'å¤„ç†å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setLlmProcessing(false)
      setLlmProcessingContext(null)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution])

  const sendSolutionMessage = useCallback(async (messageData) => {
    // ä¸å†æŠŠåŸå§‹è¾“å…¥è¿½åŠ åˆ°æ–¹æ¡ˆç«¯æ¶ˆæ¯ï¼Œä»…ç”¨äºä¸Šä¸‹æ–‡
    const userMessage = {
      type: 'user',
      text: messageData.text,
      timestamp: messageData.timestamp
    }

    // éšè—ä¿¡æ¯é€‰æ‹©é¢æ¿ï¼ˆå¦‚æœæ­£åœ¨æ˜¾ç¤ºï¼‰
    if (showMissingInfoPanel) {
      setShowMissingInfoPanel(false)
      setMissingInfoOptions([])
      setCurrentNeedsAnalysis(null)
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯åå•†åçš„è¿½é—®ã€å·²æ¥å—çš„è¿½é—®æˆ–å®¢æˆ·å›å¤ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥å‘é€ï¼Œä¸éœ€è¦AIè½¬è¯‘
    const inputText = messageData.text.trim()
    
    // æ£€æŸ¥åå•†åçš„è¿½é—®
    const negotiatedFollowUp = messages.solution.find(msg => 
      (msg.type === 'followup' || msg.type === 'intelligent_followup') && 
      msg.negotiated && 
      msg.text.trim() === inputText
    )

    // æ–°å¢ï¼šæ£€æŸ¥â€œå·²æ¥å—çš„è¿½é—®â€ï¼ˆå³ä½¿æœªè¿›å…¥åå•†ï¼‰ï¼Œä¹Ÿèµ°ç›´å‘
    const acceptedFollowUp = messages.solution.find(msg =>
      (msg.type === 'followup' || msg.type === 'intelligent_followup') &&
      msg.feedbackGiven && msg.accepted &&
      (msg.text || '').trim() === inputText
    )

    // æ£€æŸ¥éƒ¨é—¨è”ç»œæŒ‡ä»¤ä¸­çš„å®¢æˆ·å›å¤
    const customerReplyMatch = messages.solution.find(msg => 
      msg.type === 'department_contact' && 
      msg.customerReply && 
      msg.customerReply.trim() === inputText
    )

    if (negotiatedFollowUp || acceptedFollowUp) {
      console.log('ğŸ¯ æ£€æµ‹åˆ°åå•†åçš„è¿½é—®ï¼Œç›´æ¥å‘é€ç»™ç”¨æˆ·ç«¯ï¼Œè·³è¿‡AIè½¬è¯‘å¤„ç†')
      
      // ç›´æ¥å‘é€åˆ°é—®é¢˜ç«¯ï¼Œä¸ç»è¿‡AIè½¬è¯‘
      const directMessage = {
        type: 'ai_response',
        text: inputText,
        timestamp: new Date().toISOString(),
        isNegotiated: !!negotiatedFollowUp // æ ‡è®°æ˜¯å¦ä¸ºåå•†åçš„æ¶ˆæ¯
      }
      addMessage('problem', directMessage)

      // æ·»åŠ å¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿ï¼ˆæ˜¾ç¤ºè·³è¿‡è½¬è¯‘ï¼‰
      const skipMessage = {
        type: 'processing',
        title: 'è¿½é—®ç›´è¾¾ç”¨æˆ·ç«¯',
        steps: [{
          name: 'å¤„ç†è¯´æ˜',
          content: 'å·²æ¥å—/åå•†å®Œæˆçš„è¿½é—®ç›´æ¥å‘é€ç»™ç”¨æˆ·ç«¯ï¼Œæ— éœ€AIäºŒæ¬¡è½¬è¯‘'
        }],
        output: inputText,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', skipMessage)
      
      return // ç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œåç»­çš„AIå¤„ç†
    }

    if (customerReplyMatch) {
      console.log('ğŸ¯ æ£€æµ‹åˆ°å®¢æˆ·å›å¤å†…å®¹ï¼Œç›´æ¥å‘é€ç»™ç”¨æˆ·ç«¯ï¼Œè·³è¿‡AIè½¬è¯‘å¤„ç†')
      
      // ç›´æ¥å‘é€åˆ°é—®é¢˜ç«¯ï¼Œä¸ç»è¿‡AIè½¬è¯‘
      const directMessage = {
        type: 'ai_response',
        text: inputText,
        timestamp: new Date().toISOString(),
        isCustomerReply: true // æ ‡è®°ä¸ºå®¢æˆ·å›å¤æ¶ˆæ¯
      }
      addMessage('problem', directMessage)

      // æ·»åŠ å¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿ï¼ˆæ˜¾ç¤ºè·³è¿‡è½¬è¯‘ï¼‰
      const skipMessage = {
        type: 'processing',
        title: 'å®¢æˆ·å›å¤ç›´è¾¾ç”¨æˆ·ç«¯',
        steps: [{
          name: 'å¤„ç†è¯´æ˜',
          content: 'ç”Ÿæˆçš„å®¢æˆ·å›å¤ç›´æ¥å‘é€ç»™ç”¨æˆ·ç«¯ï¼Œæ— éœ€AIäºŒæ¬¡è½¬è¯‘'
        }],
        output: inputText,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', skipMessage)
      
      return // ç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œåç»­çš„AIå¤„ç†
    }

    // å¼€å§‹LLMå¤„ç†ï¼ˆæ–¹æ¡ˆç«¯ â†’ é—®é¢˜ç«¯ï¼‰
    setLlmProcessingContext('solution')
    setLlmProcessing(true)

    try {
      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å² - åŒ…å«æ‰€æœ‰çœŸå®çš„å¯¹è¯å†…å®¹
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' })),
        userMessage // åŒ…å«å½“å‰æ¶ˆæ¯ï¼ˆä¼ä¸šæ–¹è¾“å…¥ï¼‰
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // å¤„ç†æ–¹æ¡ˆç«¯å“åº”
      const llmResult = await processWithLLM({
        type: 'solution_response',
        content: messageData.text,
        context: 'solution_to_problem',
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'å¤„ç†æ–¹æ¡ˆç«¯å“åº”',
        steps: llmResult.steps,
        output: llmResult.optimizedMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // æ·»åŠ ä¼˜åŒ–åçš„å“åº”åˆ°é—®é¢˜ç«¯
      const optimizedMessage = {
        type: 'ai_response',
        text: llmResult.optimizedMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('problem', optimizedMessage)

    } catch (error) {
      console.error('LLMå¤„ç†é”™è¯¯:', error)
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage = {
        type: 'processing',
        title: 'å¤„ç†å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setLlmProcessing(false)
      setLlmProcessingContext(null)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, showMissingInfoPanel])

  // æ–°å¢ï¼šç”Ÿæˆä¼ä¸šç«¯å»ºè®®
  const generateSuggestion = useCallback(async () => {
    if (iterationProcessing) return

    setIterationProcessing(true)

    try {
      // è·å–æœ€æ–°çš„å¯¹è¯å†…å®¹
      const recentMessages = [
        ...messages.problem.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2),
        ...messages.solution.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2)
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      const currentContent = recentMessages.map(msg => msg.text).join('\n')

      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å² - åŒ…å«æ‰€æœ‰çœŸå®çš„å¯¹è¯å†…å®¹
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆå»ºè®®
      const llmResult = await processWithLLM({
        type: 'generate_suggestion',
        content: currentContent,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆä¼ä¸šç«¯å»ºè®®',
        steps: llmResult.steps,
        output: llmResult.suggestionMessage,
        structuredOutput: llmResult.structuredOutput,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // å°†å»ºè®®æ·»åŠ åˆ°æ–¹æ¡ˆç«¯ï¼ˆä½œä¸ºè¿­ä»£å†…å®¹ï¼‰
      const suggestionMessage = {
        type: 'suggestion',
        text: llmResult.suggestionMessage,
        timestamp: new Date().toISOString(),
        id: `suggestion_${Date.now()}`,
        feedbackGiven: false
      }
      addMessage('solution', suggestionMessage)

      // è¿›å…¥è¿­ä»£æ¨¡å¼
      setIterationMode(true)
      setPendingResponse(llmResult.suggestionMessage)

    } catch (error) {
      console.error('ç”Ÿæˆå»ºè®®é”™è¯¯:', error)
      const errorMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆå»ºè®®å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆå»ºè®®æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setIterationProcessing(false)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, iterationProcessing])

  // æ–°å¢ï¼šç”Ÿæˆä¼ä¸šç«¯è¿½é—®
  const generateFollowUp = useCallback(async () => {
    if (iterationProcessing) return

    setIterationProcessing(true)

    try {
      // è·å–æœ€æ–°çš„å¯¹è¯å†…å®¹
      const recentMessages = [
        ...messages.problem.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2),
        ...messages.solution.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2)
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      const currentContent = recentMessages.map(msg => msg.text).join('\n')

      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å² - åŒ…å«æ‰€æœ‰çœŸå®çš„å¯¹è¯å†…å®¹
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆè¿½é—®
      const llmResult = await processWithLLM({
        type: 'generate_followup',
        content: currentContent,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆä¼ä¸šç«¯è¿½é—®',
        steps: llmResult.steps,
        output: llmResult.followUpMessage,
        structuredOutput: llmResult.structuredOutput,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // å°†è¿½é—®æ·»åŠ åˆ°æ–¹æ¡ˆç«¯ï¼ˆä½œä¸ºè¿­ä»£å†…å®¹ï¼‰
      const followUpMessage = {
        type: 'followup',
        text: llmResult.followUpMessage,
        timestamp: new Date().toISOString(),
        id: `followup_${Date.now()}`,
        feedbackGiven: false
      }
      addMessage('solution', followUpMessage)

      // è¿›å…¥è¿­ä»£æ¨¡å¼
      setIterationMode(true)
      setPendingResponse(llmResult.followUpMessage)

    } catch (error) {
      console.error('ç”Ÿæˆè¿½é—®é”™è¯¯:', error)
      const errorMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆè¿½é—®å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆè¿½é—®æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setIterationProcessing(false)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, iterationProcessing])

  // æ–°å¢ï¼šç¡®è®¤å‘é€æœ€ç»ˆå“åº”
  const confirmSendResponse = useCallback(async (finalResponse) => {
    if (llmProcessing) return

    // é¦–å…ˆæ·»åŠ ç”¨æˆ·çš„æœ€ç»ˆå“åº”æ¶ˆæ¯åˆ°æ–¹æ¡ˆç«¯
    const userFinalMessage = {
      type: 'user',
      text: finalResponse,
      timestamp: new Date().toISOString()
    }
    addMessage('solution', userFinalMessage)

    setLlmProcessingContext('solution')
    setLlmProcessing(true)

    try {
      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å² - åŒ…å«æ‰€æœ‰çœŸå®çš„å¯¹è¯å†…å®¹
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' })),
        userFinalMessage // åŒ…å«ç”¨æˆ·çš„æœ€ç»ˆå“åº”
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // å¤„ç†æœ€ç»ˆå“åº”
      const llmResult = await processWithLLM({
        type: 'solution_response',
        content: finalResponse,
        context: 'solution_to_problem',
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'å¤„ç†æœ€ç»ˆå“åº”',
        steps: llmResult.steps,
        output: llmResult.optimizedMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // æ·»åŠ ä¼˜åŒ–åçš„å“åº”åˆ°é—®é¢˜ç«¯
      const optimizedMessage = {
        type: 'ai_response',
        text: llmResult.optimizedMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('problem', optimizedMessage)

      // é€€å‡ºè¿­ä»£æ¨¡å¼
      setIterationMode(false)
      setPendingResponse(null)

    } catch (error) {
      console.error('ç¡®è®¤å‘é€é”™è¯¯:', error)
      const errorMessage = {
        type: 'processing',
        title: 'å¤„ç†æœ€ç»ˆå“åº”å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œå¤„ç†æœ€ç»ˆå“åº”æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setLlmProcessing(false)
      setLlmProcessingContext(null)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, llmProcessing])

  // æ–°å¢ï¼šå–æ¶ˆè¿­ä»£æ¨¡å¼
  const cancelIteration = useCallback(() => {
    setIterationMode(false)
    setPendingResponse(null)
  }, [])

  // æ–°å¢ï¼šå¤„ç†ä¿¡æ¯é€‰é¡¹å‹¾é€‰
  const toggleMissingInfoOption = useCallback((index) => {
    setMissingInfoOptions(prev => 
      prev.map((option, i) => 
        i === index ? { ...option, selected: !option.selected } : option
      )
    )
  }, [])

  // æ–°å¢ï¼šç”ŸæˆåŸºäºé€‰ä¸­ä¿¡æ¯çš„è¿½é—®
  const generateFollowUpBySelectedInfo = useCallback(async () => {
    if (!currentNeedsAnalysis || iterationProcessing) return
    
    const selectedOptions = missingInfoOptions.filter(option => option.selected)
    if (selectedOptions.length === 0) return

    setIterationProcessing(true)

    try {
      // ç”Ÿæˆè¿½é—®
      const llmResult = await processWithLLM({
        type: 'generate_questions_by_selected_info',
        content: {
          originalContent: currentNeedsAnalysis.originalContent,
          selectedInfoItems: selectedOptions
        },
        scenario: currentScenario,
        chatHistory: currentNeedsAnalysis.chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆæ™ºèƒ½è¿½é—®',
        steps: [
          {
            name: 'é€‰ä¸­ä¿¡æ¯',
            content: selectedOptions.map(opt => `${opt.name}ï¼š${opt.description}`).join('\n')
          },
          {
            name: 'ç”Ÿæˆè¿½é—®',
            content: llmResult
          }
        ],
        output: llmResult,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // å°†æ™ºèƒ½ç”Ÿæˆçš„è¿½é—®æ·»åŠ åˆ°æ–¹æ¡ˆç«¯ï¼Œæ”¯æŒåå•†ã€æ‹’ç»ã€é‡‡çº³
      const intelligentFollowUpMessage = {
        id: Date.now() + Math.random(),
        type: 'intelligent_followup',
        text: llmResult,
        timestamp: new Date().toISOString(),
        selectedInfo: selectedOptions,
        feedbackGiven: false,
        accepted: false,
        negotiating: false,
        negotiated: false
      }
      addMessage('solution', intelligentFollowUpMessage)
      setShowMissingInfoPanel(false)

    } catch (error) {
      console.error('ç”Ÿæˆè¿½é—®é”™è¯¯:', error)
      const errorMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆè¿½é—®å‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆè¿½é—®æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setIterationProcessing(false)
    }
  }, [currentNeedsAnalysis, missingInfoOptions, currentScenario, iterationProcessing, addMessage])

  // æ–°å¢ï¼šè·³è¿‡ä¿¡æ¯æ”¶é›†ï¼Œç›´æ¥å›å¤
  const skipInfoCollection = useCallback(() => {
    setShowMissingInfoPanel(false)
    setMissingInfoOptions([])
    setCurrentNeedsAnalysis(null)
  }, [])

  // æ–°å¢ï¼šç®€å•çš„æ™ºèƒ½è¿½é—®ç”Ÿæˆï¼ˆåŸºäºå½“å‰å¯¹è¯ï¼‰
  const generateSimpleIntelligentFollowUp = useCallback(async () => {
    if (llmProcessing || iterationProcessing) return
    
    setIterationProcessing(true)
    
    try {
      // è·å–æœ€è¿‘çš„å¯¹è¯å†…å®¹
      const recentProblemMessages = messages.problem.slice(-3)
      const recentSolutionMessages = messages.solution.slice(-3)
      
      const content = [...recentProblemMessages, ...recentSolutionMessages]
        .sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))
        .map(msg => msg.text || msg.output)
        .join('\n')
      
      if (!content.trim()) {
        console.log('æ²¡æœ‰è¶³å¤Ÿçš„å¯¹è¯å†…å®¹ç”Ÿæˆæ™ºèƒ½è¿½é—®')
        setIterationProcessing(false)
        return
      }

      // è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½è¿½é—®
      const llmResult = await processWithLLM({
        type: 'generate_followup',
        content: content,
        scenario: currentScenario,
        chatHistory: [...recentProblemMessages, ...recentSolutionMessages]
      })

      // æ·»åŠ åˆ°LLMé¢æ¿æ˜¾ç¤º
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆæ™ºèƒ½è¿½é—®',
        steps: llmResult.steps,
        output: llmResult.followUpMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      console.log('âœ… æ™ºèƒ½è¿½é—®ç”Ÿæˆå®Œæˆ:', llmResult.followUpMessage)
      
    } catch (error) {
      console.error('ç”Ÿæˆæ™ºèƒ½è¿½é—®é”™è¯¯:', error)
    } finally {
      setIterationProcessing(false)
    }
  }, [llmProcessing, iterationProcessing, messages.problem, messages.solution, currentScenario, addMessage])

  // æ–°å¢ï¼šç‹¬ç«‹çš„æ™ºèƒ½éœ€æ±‚åˆ†æï¼ˆåŸºäºå½“å‰å¯¹è¯ï¼‰
  const generateIntelligentNeedsAnalysis = useCallback(async () => {
    if (llmProcessing || iterationProcessing) return
    
    setIterationProcessing(true)
    
    try {
      // è·å–æœ€è¿‘çš„é—®é¢˜ç«¯æ¶ˆæ¯ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰
      const recentProblemMessages = messages.problem.filter(msg => msg.type === 'user').slice(-2)
      
      if (recentProblemMessages.length === 0) {
        console.log('æ²¡æœ‰ç”¨æˆ·è¾“å…¥å†…å®¹è¿›è¡Œéœ€æ±‚åˆ†æ')
        setIterationProcessing(false)
        return
      }

      // ä½¿ç”¨æœ€æ–°çš„ç”¨æˆ·è¾“å…¥è¿›è¡Œåˆ†æ
      const latestUserMessage = recentProblemMessages[recentProblemMessages.length - 1]
      
      // æ„å»ºèŠå¤©å†å²
      const chatHistory = [
        ...messages.problem.slice(-3),
        ...messages.solution.slice(-3)
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // è°ƒç”¨æ™ºèƒ½éœ€æ±‚åˆ†æ
      const llmResult = await processWithLLM({
        type: 'analyze_needs_with_missing_info',
        content: latestUserMessage.text,
        image: latestUserMessage.image,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ åˆ°LLMé¢æ¿æ˜¾ç¤º
      const llmMessage = {
        type: 'processing',
        title: 'æ™ºèƒ½éœ€æ±‚åˆ†æ',
        steps: [
          {
            name: 'éœ€æ±‚ç†è§£',
            content: llmResult.needsUnderstanding
          },
          {
            name: 'ä¿¡æ¯é€‰é¡¹',
            content: llmResult.missingInfoOptions.map(opt => `${opt.name}ï¼š${opt.description}`).join('\n')
          },
          {
            name: 'éœ€æ±‚è½¬è¯‘',
            content: llmResult.translation
          }
        ],
        output: llmResult.needsUnderstanding,
        timestamp: new Date().toISOString(),
        structuredOutput: llmResult.structuredOutput
      }
      addMessage('llm', llmMessage)

      console.log('âœ… æ™ºèƒ½éœ€æ±‚åˆ†æå®Œæˆ:', llmResult)
      
    } catch (error) {
      console.error('æ™ºèƒ½éœ€æ±‚åˆ†æé”™è¯¯:', error)
    } finally {
      setIterationProcessing(false)
    }
  }, [llmProcessing, iterationProcessing, messages.problem, messages.solution, currentScenario, addMessage])

  // æ–°å¢ï¼šæ¥å—å»ºè®®
  const acceptSuggestion = useCallback((suggestionId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === suggestionId 
          ? { ...msg, feedbackGiven: true, accepted: true }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šä¸AIåå•†å»ºè®®
  const negotiateSuggestion = useCallback((suggestionId) => {
    // æ ‡è®°å»ºè®®è¿›å…¥åå•†æ¨¡å¼
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === suggestionId 
          ? { ...msg, negotiating: true }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå–æ¶ˆåå•†æ¨¡å¼
  const cancelNegotiation = useCallback((suggestionId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === suggestionId 
          ? { ...msg, negotiating: false }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå‘é€åå•†è¯·æ±‚
  const sendNegotiationRequest = useCallback(async (suggestionId, negotiationText, onUpdateContent) => {
    if (!negotiationText.trim()) return

    console.log('ğŸ”„ å¼€å§‹å¤„ç†å»ºè®®åå•†è¯·æ±‚:', { suggestionId, negotiationText })

    try {
      // æ ¹æ®messageIdæ ¼å¼åˆ¤æ–­æ˜¯ä»å“ªä¸ªæ¶ˆæ¯æ•°ç»„æŸ¥æ‰¾
      let originalSuggestion
      if (suggestionId.includes('_suggestion')) {
        // è¿™æ˜¯æ¥è‡ªLLMé¢æ¿çš„æ¶ˆæ¯ï¼Œä»messages.llmä¸­æŸ¥æ‰¾
        const messageIndex = parseInt(suggestionId.split('_')[0])
        originalSuggestion = messages.llm[messageIndex]
      } else {
        // è¿™æ˜¯æ¥è‡ªsolutioné¢æ¿çš„æ¶ˆæ¯
        originalSuggestion = messages.solution.find(msg => msg.id === suggestionId)
      }
      
      if (!originalSuggestion) {
        console.error('âŒ æœªæ‰¾åˆ°åŸå§‹å»ºè®®', { 
          suggestionId, 
          messagesLlmLength: messages.llm.length,
          messagesSolutionLength: messages.solution.length 
        })
        return
      }
      
      console.log('âœ… æ‰¾åˆ°åŸå§‹å»ºè®®:', { 
        suggestionId, 
        originalSuggestionText: originalSuggestion.text || originalSuggestion.output 
      })

      // æ„å»ºåå•†ä¸Šä¸‹æ–‡
      const chatHistory = [
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆåå•†åçš„å»ºè®®
      const llmResult = await processWithLLM({
        type: 'negotiate_suggestion',
        content: {
          originalSuggestion: originalSuggestion.text || originalSuggestion.output,
          negotiationRequest: negotiationText,
          negotiationHistory: originalSuggestion.negotiationHistory || []
        },
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // ä¸å†æ·»åŠ å¤„ç†è¯´æ˜åˆ°LLMé¢æ¿ï¼Œç›´æ¥æ›´æ–°åŸå†…å®¹

      // è°ƒç”¨å›è°ƒå‡½æ•°æ›´æ–°æ˜¾ç¤ºå†…å®¹
      if (onUpdateContent && typeof onUpdateContent === 'function') {
        console.log('ğŸ”„ è°ƒç”¨å›è°ƒå‡½æ•°æ›´æ–°å»ºè®®å†…å®¹:', llmResult.suggestionMessage)
        onUpdateContent(llmResult.suggestionMessage)
      } else {
        console.warn('âš ï¸ æœªæä¾›å›è°ƒå‡½æ•°æˆ–å›è°ƒå‡½æ•°æ— æ•ˆ')
      }
      
      console.log('âœ… å»ºè®®åå•†å¤„ç†å®Œæˆ')

      // æ›´æ–°åŸå»ºè®®ä¸ºåå•†åçš„ç‰ˆæœ¬ï¼Œä¿ç•™åå•†å†å²
      setMessages(prev => ({
        ...prev,
        solution: prev.solution.map(msg => 
          msg.id === suggestionId 
            ? { 
                ...msg, 
                text: llmResult.suggestionMessage,
                negotiating: false,
                negotiated: true,
                negotiationHistory: [
                  ...(msg.negotiationHistory || []),
                  {
                    previousText: msg.negotiationHistory?.length > 0 ? msg.text : (msg.originalText || msg.text),
                    negotiationRequest: negotiationText,
                    timestamp: new Date().toISOString()
                  }
                ],
                originalText: msg.originalText || originalSuggestion.text
              }
            : msg
        )
      }))

    } catch (error) {
      console.error('åå•†å»ºè®®é”™è¯¯:', error)
      // åå•†å¤±è´¥ï¼Œé€€å‡ºåå•†æ¨¡å¼
      cancelNegotiation(suggestionId)
    }
  }, [messages.problem, messages.solution, currentScenario, addMessage, cancelNegotiation])

  // æ–°å¢ï¼šæ‹’ç»å»ºè®®å¹¶é‡æ–°ç”Ÿæˆ
  const rejectSuggestion = useCallback(async (suggestionId) => {
    // æ ‡è®°å»ºè®®ä¸ºå·²æ‹’ç»
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === suggestionId 
          ? { ...msg, feedbackGiven: true, accepted: false }
          : msg
      )
    }))

    // é‡æ–°ç”Ÿæˆå»ºè®®
    await generateSuggestion()
  }, [generateSuggestion])

  // æ–°å¢ï¼šæ¥å—è¿½é—®
  const acceptFollowUp = useCallback((followUpId, onSetInput) => {
    const followUpMessage = messages.solution.find(msg => msg.id === followUpId)
    if (!followUpMessage) return

    // æ ‡è®°ä¸ºå·²æ¥å—
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, feedbackGiven: true, accepted: true }
          : msg
      )
    }))

    // å°†è¿½é—®å†…å®¹å¡«å…¥è¾“å…¥æ¡†
    if (onSetInput && typeof onSetInput === 'function') {
      onSetInput(followUpMessage.text)
    }

    // è®¾ä¸ºç›´å‘å€™é€‰ï¼Œç­‰å¾…å¯¹æ¯”ç¡®è®¤
    setDirectSendCandidate({
      type: 'followup',
      sourceMessageId: followUpId,
      sourceText: followUpMessage.text,
      createdAt: new Date().toISOString()
    })
  }, [messages.solution])

  // æ–°å¢ï¼šä¸AIåå•†è¿½é—®
  const negotiateFollowUp = useCallback((followUpId) => {
    // æ ‡è®°è¿½é—®è¿›å…¥åå•†æ¨¡å¼
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, negotiating: true }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå–æ¶ˆè¿½é—®åå•†æ¨¡å¼
  const cancelFollowUpNegotiation = useCallback((followUpId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, negotiating: false }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå‘é€è¿½é—®åå•†è¯·æ±‚
  const sendFollowUpNegotiationRequest = useCallback(async (followUpId, negotiationText, onUpdateContent) => {
    if (!negotiationText.trim()) return

    console.log('ğŸ”„ å¼€å§‹å¤„ç†è¿½é—®åå•†è¯·æ±‚:', { followUpId, negotiationText })

    try {
      // æ ¹æ®messageIdæ ¼å¼åˆ¤æ–­æ˜¯ä»å“ªä¸ªæ¶ˆæ¯æ•°ç»„æŸ¥æ‰¾
      let originalFollowUp
      if (followUpId.includes('_followup')) {
        // è¿™æ˜¯æ¥è‡ªLLMé¢æ¿çš„æ¶ˆæ¯ï¼Œä»messages.llmä¸­æŸ¥æ‰¾
        const messageIndex = parseInt(followUpId.split('_')[0])
        originalFollowUp = messages.llm[messageIndex]
      } else {
        // è¿™æ˜¯æ¥è‡ªsolutioné¢æ¿çš„æ¶ˆæ¯
        originalFollowUp = messages.solution.find(msg => msg.id === followUpId)
      }
      
      if (!originalFollowUp) {
        console.error('æœªæ‰¾åˆ°åŸå§‹è¿½é—®ï¼ŒfollowUpId:', followUpId)
        return
      }

      // æ„å»ºåå•†ä¸Šä¸‹æ–‡
      const chatHistory = [
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆåå•†åçš„è¿½é—®
      const llmResult = await processWithLLM({
        type: 'negotiate_followup',
        content: {
          originalFollowUp: originalFollowUp.text || originalFollowUp.output,
          negotiationRequest: negotiationText,
          negotiationHistory: originalFollowUp.negotiationHistory || []
        },
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // ä¸å†æ·»åŠ å¤„ç†è¯´æ˜åˆ°LLMé¢æ¿ï¼Œç›´æ¥æ›´æ–°åŸå†…å®¹

      // è°ƒç”¨å›è°ƒå‡½æ•°æ›´æ–°æ˜¾ç¤ºå†…å®¹
      if (onUpdateContent && typeof onUpdateContent === 'function') {
        onUpdateContent(llmResult.followUpMessage)
      }

      // æ›´æ–°åŸè¿½é—®ä¸ºåå•†åçš„ç‰ˆæœ¬ï¼Œä¿ç•™åå•†å†å²
      setMessages(prev => ({
        ...prev,
        solution: prev.solution.map(msg => 
          msg.id === followUpId 
            ? { 
                ...msg, 
                text: llmResult.followUpMessage,
                negotiating: false,
                negotiated: true,
                negotiationHistory: [
                  ...(msg.negotiationHistory || []),
                  {
                    previousText: msg.negotiationHistory?.length > 0 ? msg.text : (msg.originalText || msg.text),
                    negotiationRequest: negotiationText,
                    timestamp: new Date().toISOString()
                  }
                ],
                originalText: msg.originalText || originalFollowUp.text
              }
            : msg
        )
      }))

      // åå•†å®Œæˆåï¼Œå°†åå•†åçš„è¿½é—®è‡ªåŠ¨å¡«å…¥è¾“å…¥æ¡†
      if (onSetInput && typeof onSetInput === 'function') {
        onSetInput(llmResult.followUpMessage)
      }

    } catch (error) {
      console.error('åå•†è¿½é—®é”™è¯¯:', error)
      // åå•†å¤±è´¥ï¼Œé€€å‡ºåå•†æ¨¡å¼
      cancelFollowUpNegotiation(followUpId)
    }
  }, [messages.problem, messages.solution, currentScenario, addMessage, cancelFollowUpNegotiation])

  // æ–°å¢ï¼šæ‹’ç»è¿½é—®å¹¶é‡æ–°ç”Ÿæˆ
  const rejectFollowUp = useCallback(async (followUpId) => {
    // æ ‡è®°è¿½é—®ä¸ºå·²æ‹’ç»
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, feedbackGiven: true, accepted: false }
          : msg
      )
    }))

    // é‡æ–°ç”Ÿæˆè¿½é—®
    await generateFollowUp()
  }, [generateFollowUp])

  // æ–°å¢ï¼šæ¥å—æ™ºèƒ½è¿½é—®
  const acceptIntelligentFollowUp = useCallback((followUpId, onSetInput) => {
    const followUpMessage = messages.solution.find(msg => msg.id === followUpId)
    if (!followUpMessage) return

    // æ ‡è®°ä¸ºå·²æ¥å—
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, feedbackGiven: true, accepted: true }
          : msg
      )
    }))

    // å°†è¿½é—®å†…å®¹å¡«å…¥è¾“å…¥æ¡†
    if (onSetInput && typeof onSetInput === 'function') {
      onSetInput(followUpMessage.text)
    }

    // è®¾ä¸ºç›´å‘å€™é€‰ï¼Œç­‰å¾…å¯¹æ¯”ç¡®è®¤
    setDirectSendCandidate({
      type: 'intelligent_followup',
      sourceMessageId: followUpId,
      sourceText: followUpMessage.text,
      createdAt: new Date().toISOString()
    })
  }, [messages.solution])

  // æ–°å¢ï¼šç¡®è®¤ç›´å‘åˆ°é—®é¢˜ç«¯ï¼ˆä¸è½¬è¯‘ï¼‰
  const confirmDirectSendToProblem = useCallback((finalText) => {
    if (!finalText || !finalText.trim()) return

    // ç›´æ¥å‘é€åˆ°é—®é¢˜ç«¯
    const directMessage = {
      type: 'ai_response',
      text: finalText.trim(),
      timestamp: new Date().toISOString(),
      isDirectFollowUp: true,
      candidateType: directSendCandidate?.type
    }
    addMessage('problem', directMessage)

    // åœ¨ä¸­ä»‹é¢æ¿è®°å½•ä¸€æ¬¡å¤„ç†è¯´æ˜
    const infoMessage = {
      type: 'processing',
      title: 'è¿½é—®ç›´è¾¾ç”¨æˆ·ç«¯',
      steps: [{
        name: 'å¤„ç†è¯´æ˜',
        content: 'å·²ç¡®è®¤ç›´å‘ï¼Œè·³è¿‡AIè½¬è¯‘'
      }],
      output: finalText.trim(),
      timestamp: new Date().toISOString()
    }
    addMessage('llm', infoMessage)

    // æ¸…ç©ºå€™é€‰
    setDirectSendCandidate(null)
  }, [addMessage, directSendCandidate])

  // æ–°å¢ï¼šå–æ¶ˆç›´å‘æµç¨‹ï¼Œä¿ç•™è¾“å…¥æ¡†å†…å®¹
  const cancelDirectSend = useCallback(() => {
    setDirectSendCandidate(null)
  }, [])

  // æ–°å¢ï¼šå¤–éƒ¨å‡†å¤‡ç›´å‘å€™é€‰ï¼ˆç”¨äºâ€œåº”ç”¨å®¢æˆ·å›å¤â€æŒ‰é’®ï¼‰
  const prepareDirectSendCandidate = useCallback((candidate) => {
    if (!candidate || !candidate.sourceText) return
    setDirectSendCandidate({
      type: candidate.type || 'customer_reply',
      sourceMessageId: candidate.sourceMessageId,
      sourceText: candidate.sourceText,
      createdAt: new Date().toISOString()
    })
  }, [])

  // æ–°å¢ï¼šæ‹’ç»æ™ºèƒ½è¿½é—®
  const rejectIntelligentFollowUp = useCallback(async (followUpId) => {
    // æ ‡è®°è¿½é—®ä¸ºå·²æ‹’ç»
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, feedbackGiven: true, accepted: false }
          : msg
      )
    }))

    // å¯ä»¥é€‰æ‹©é‡æ–°ç”Ÿæˆæˆ–è€…å›åˆ°ä¿¡æ¯é€‰æ‹©ç•Œé¢
    setShowMissingInfoPanel(true)
  }, [])

  // æ–°å¢ï¼šåå•†æ™ºèƒ½è¿½é—®
  const negotiateIntelligentFollowUp = useCallback((followUpId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, negotiating: true }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå–æ¶ˆæ™ºèƒ½è¿½é—®åå•†
  const cancelIntelligentFollowUpNegotiation = useCallback((followUpId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === followUpId 
          ? { ...msg, negotiating: false }
          : msg
      )
    }))
  }, [])

  // æ–°å¢ï¼šå‘é€æ™ºèƒ½è¿½é—®åå•†è¯·æ±‚
  const sendIntelligentFollowUpNegotiationRequest = useCallback(async (followUpId, negotiationText, onSetInput) => {
    if (!negotiationText.trim()) return

    try {
      // è·å–åŸå§‹è¿½é—®
      const originalFollowUp = messages.solution.find(msg => msg.id === followUpId)
      if (!originalFollowUp) return

      // æ„å»ºåå•†ä¸Šä¸‹æ–‡
      const chatHistory = [
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆåå•†åçš„è¿½é—®
      const llmResult = await processWithLLM({
        type: 'negotiate_followup',
        content: {
          originalFollowUp: originalFollowUp.text || originalFollowUp.output,
          negotiationRequest: negotiationText,
          negotiationHistory: originalFollowUp.negotiationHistory || []
        },
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'åå•†ä¿®æ”¹æ™ºèƒ½è¿½é—®',
        steps: llmResult.steps,
        output: llmResult.followUpMessage,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // æ›´æ–°åŸè¿½é—®ä¸ºåå•†åçš„ç‰ˆæœ¬ï¼Œä¿ç•™åå•†å†å²
      setMessages(prev => ({
        ...prev,
        solution: prev.solution.map(msg => 
          msg.id === followUpId 
            ? { 
                ...msg, 
                text: llmResult.followUpMessage,
                negotiating: false,
                negotiated: true,
                negotiationHistory: [
                  ...(msg.negotiationHistory || []),
                  {
                    previousText: msg.negotiationHistory?.length > 0 ? msg.text : (msg.originalText || msg.text),
                    negotiationRequest: negotiationText,
                    timestamp: new Date().toISOString()
                  }
                ],
                originalText: msg.originalText || originalFollowUp.text
              }
            : msg
        )
      }))

      // åå•†å®Œæˆåï¼Œå°†åå•†åçš„è¿½é—®è‡ªåŠ¨å¡«å…¥è¾“å…¥æ¡†
      if (onSetInput && typeof onSetInput === 'function') {
        onSetInput(llmResult.followUpMessage)
      }

    } catch (error) {
      console.error('åå•†æ™ºèƒ½è¿½é—®é”™è¯¯:', error)
      // åå•†å¤±è´¥ï¼Œé€€å‡ºåå•†æ¨¡å¼
      cancelIntelligentFollowUpNegotiation(followUpId)
    }
  }, [messages.problem, messages.solution, currentScenario, addMessage, cancelIntelligentFollowUpNegotiation])

  // ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤
  // AIå¯¹è¯åŠŸèƒ½
  const chatWithAI = useCallback(async (question) => {
    console.log('ğŸ¤– å¼€å§‹AIå¯¹è¯:', { question })
    // ä¸ä½¿ç”¨setLlmProcessingï¼Œé¿å…å½±å“å…¶ä»–é¢æ¿çš„å¤„ç†çŠ¶æ€

    try {
      // æ„å»ºèŠå¤©å†å²ä¸Šä¸‹æ–‡
      const chatHistory = [
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // è°ƒç”¨LLMè¿›è¡ŒAIå¯¹è¯
      const llmResult = await processWithLLM({
        type: 'ai_chat',
        content: question,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ AIå¯¹è¯æ¶ˆæ¯åˆ°ä¸­ä»‹é¢æ¿
      const aiChatMessage = {
        type: 'ai_chat',
        title: 'AIå¯¹è¯',
        question: question,
        answer: llmResult.answer,
        timestamp: new Date().toISOString(),
        error: llmResult.error
      }
      addMessage('llm', aiChatMessage)

      console.log('âœ… AIå¯¹è¯å®Œæˆ:', { answer: llmResult.answer })

    } catch (error) {
      console.error('âŒ AIå¯¹è¯å¤±è´¥:', error)
      
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage = {
        type: 'ai_chat',
        title: 'AIå¯¹è¯',
        question: question,
        answer: 'æŠ±æ­‰ï¼ŒAIå¯¹è¯åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚',
        timestamp: new Date().toISOString(),
        error: true
      }
      addMessage('llm', errorMessage)
    } finally {
      // ä¸éœ€è¦é‡ç½®setLlmProcessingï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰è®¾ç½®å®ƒ
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution])

  // ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤ï¼ˆä»…è”ç»œæŒ‡ä»¤ï¼‰
  const generateDepartmentContactOnly = useCallback(async () => {
    if (iterationProcessing) return

    setIterationProcessing(true)

    try {
      // è·å–æœ€æ–°çš„å¯¹è¯å†…å®¹ä½œä¸ºè”ç»œæŒ‡ä»¤çš„åŸºç¡€
      const recentMessages = [
        ...messages.problem.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2),
        ...messages.solution.filter(m => m.type === 'user' || m.type === 'ai_response').slice(-2)
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      const currentContent = recentMessages.map(msg => msg.text).join('\n') || 'åŸºäºå½“å‰å¯¹è¯ç”Ÿæˆè”ç»œæŒ‡ä»¤'

      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å²
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤
      const llmResult = await processWithLLM({
        type: 'generate_department_contact_only',
        content: currentContent,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆéƒ¨é—¨è”ç»œ',
        steps: llmResult.steps,
        structuredOutput: llmResult.structuredOutput,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      console.log('âœ… éƒ¨é—¨è”ç»œæŒ‡ä»¤ç”Ÿæˆå®Œæˆ')

    } catch (error) {
      console.error('ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤æ—¶å‡ºé”™:', error)
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆéƒ¨é—¨è”ç»œå‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setIterationProcessing(false)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, iterationProcessing])

  const generateDepartmentContact = useCallback(async (suggestion) => {
    if (iterationProcessing) return

    setIterationProcessing(true)

    try {
      // æ„å»ºå®Œæ•´çš„èŠå¤©å†å²
      const chatHistory = [
        // é—®é¢˜ç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šç”¨æˆ·è¾“å…¥ + AIä¼˜åŒ–åçš„å›å¤
        ...messages.problem
          .filter(msg => msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'problem' })),
        // æ–¹æ¡ˆç«¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼šAIè½¬è¯‘çš„è¯·æ±‚ + ä¼ä¸šç”¨æˆ·è¾“å…¥ + AIå›å¤
        ...messages.solution
          .filter(msg => msg.type === 'llm_request' || msg.type === 'user' || msg.type === 'ai_response')
          .map(msg => ({ ...msg, panel: 'solution' }))
      ].sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp))

      // ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤
      const llmResult = await processWithLLM({
        type: 'generate_department_contact',
        content: suggestion,
        scenario: currentScenario,
        chatHistory: chatHistory
      })

      // æ·»åŠ LLMå¤„ç†è¿‡ç¨‹åˆ°ä¸­ä»‹é¢æ¿
      const llmMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆå®¢æˆ·å›å¤å’Œéƒ¨é—¨è”ç»œ',
        steps: llmResult.steps,
        output: `å®¢æˆ·å›å¤ï¼š${llmResult.customerReply}\n\nè”ç»œæŒ‡ä»¤ï¼š${llmResult.contactInstruction}`,
        structuredOutput: llmResult.structuredOutput,
        timestamp: new Date().toISOString()
      }
      addMessage('llm', llmMessage)

      // å°†è”ç»œæŒ‡ä»¤æ·»åŠ åˆ°æ–¹æ¡ˆç«¯ï¼ˆä½œä¸ºç‰¹æ®Šæ¶ˆæ¯ç±»å‹ï¼‰
      const contactMessage = {
        type: 'department_contact',
        customerReply: llmResult.customerReply,
        contactInstruction: llmResult.contactInstruction,
        timestamp: new Date().toISOString(),
        id: `contact_${Date.now()}`,
        instructionSent: false, // åˆå§‹åŒ–ä¸ºæœªå‘é€çŠ¶æ€
        sentTimestamp: null,
        customerReplyApplied: false, // åˆå§‹åŒ–ä¸ºæœªåº”ç”¨çŠ¶æ€
        appliedTimestamp: null
      }
      addMessage('solution', contactMessage)

    } catch (error) {
      console.error('ç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤æ—¶å‡ºé”™:', error)
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage = {
        type: 'processing',
        title: 'ç”Ÿæˆå®¢æˆ·å›å¤å’Œéƒ¨é—¨è”ç»œå‡ºé”™',
        steps: [{
          name: 'é”™è¯¯ä¿¡æ¯',
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆéƒ¨é—¨è”ç»œæŒ‡ä»¤æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        }],
        timestamp: new Date().toISOString()
      }
      addMessage('llm', errorMessage)
    } finally {
      setIterationProcessing(false)
    }
  }, [addMessage, currentScenario, messages.problem, messages.solution, iterationProcessing])

  // æ ‡è®°è”ç»œæŒ‡ä»¤ä¸ºå·²å‘é€
  const markContactInstructionSent = useCallback((contactId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === contactId && msg.type === 'department_contact' ? {
          ...msg,
          instructionSent: true,
          sentTimestamp: new Date().toISOString()
        } : msg
      )
    }))
  }, [])

  // æ ‡è®°å®¢æˆ·å›å¤ä¸ºå·²åº”ç”¨
  const markCustomerReplyApplied = useCallback((contactId) => {
    setMessages(prev => ({
      ...prev,
      solution: prev.solution.map(msg => 
        msg.id === contactId && msg.type === 'department_contact' ? {
          ...msg,
          customerReplyApplied: true,
          appliedTimestamp: new Date().toISOString()
        } : msg
      )
    }))
    console.log('âœ… å®¢æˆ·å›å¤å·²æ ‡è®°ä¸ºåº”ç”¨çŠ¶æ€', contactId)
  }, [])

  // æ–°å¢ï¼šæ¸…ç©ºæ‰€æœ‰çŠ¶æ€
  const clearAllStates = useCallback(() => {
    setMessages({
      problem: [],
      llm: [],
      solution: []
    })
    setIterationMode(false)
    setPendingResponse(null)
    setMissingInfoOptions([])
    setShowMissingInfoPanel(false)
    setCurrentNeedsAnalysis(null)
  }, [])

  return {
    messages,
    llmProcessing,
    llmProcessingContext,
    iterationProcessing,
    iterationMode,
    pendingResponse,
    directSendCandidate,
    // æ–°å¢çš„çŠ¶æ€å’Œæ–¹æ³•
    missingInfoOptions,
    showMissingInfoPanel,
    currentNeedsAnalysis,
    toggleMissingInfoOption,
    generateFollowUpBySelectedInfo,
    generateSimpleIntelligentFollowUp,
    generateIntelligentNeedsAnalysis,
    skipInfoCollection,
    // å»ºè®®åé¦ˆç›¸å…³æ–¹æ³•
    acceptSuggestion,
    negotiateSuggestion,
    cancelNegotiation,
    sendNegotiationRequest,
    rejectSuggestion,
    // è¿½é—®åé¦ˆç›¸å…³æ–¹æ³•
    acceptFollowUp,
    negotiateFollowUp,
    cancelFollowUpNegotiation,
    sendFollowUpNegotiationRequest,
    rejectFollowUp,
    confirmDirectSendToProblem,
    cancelDirectSend,
    prepareDirectSendCandidate,
    // æ™ºèƒ½è¿½é—®åé¦ˆç›¸å…³æ–¹æ³•
    acceptIntelligentFollowUp,
    negotiateIntelligentFollowUp,
    cancelIntelligentFollowUpNegotiation,
    sendIntelligentFollowUpNegotiationRequest,
    rejectIntelligentFollowUp,
    // åŸæœ‰æ–¹æ³•
    sendProblemMessage,
    sendCustomerReplyToProblem,
    sendSolutionMessage,
    generateSuggestion,
    generateFollowUp,
    generateDepartmentContact,
    generateDepartmentContactOnly,
    chatWithAI,
    markContactInstructionSent,
    markCustomerReplyApplied,
    confirmSendResponse,
    cancelIteration,
    clearMessages: clearAllStates
  }
}